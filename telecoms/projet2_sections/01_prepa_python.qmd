---
title: "P2 – Ingestion & Préparation (Python)"
subtitle: "France 2024 : où se situe la qualité de service mobile face aux standards internationaux ?"
format:
  html:
    toc: true
    toc-depth: 3
    number-sections: false
    code-fold: false
  gfm: default           # (optionnel) export Markdown GitHub
execute:
  echo: false
  warning: false
  message: false
---

::: {.callout-note}
**Exports** :
- HTML rendu par Quarto (page actuelle)
- Markdown GitHub : `01_prepa_python.md`
:::

## 1) Contexte & objectifs

Ce document prépare et standardise les données **ARCEP 2024**, **ITU**, **Banque Mondiale** (et dérivés), puis **produit exactement** les fichiers nettoyés suivants :

- `arcep_2024_indicateurs_globaux_clean.csv`
- `arcep_2024_indicateurs_globaux_complet.csv`
- `arcep_2024_indicateurs_globaux_simplifie.csv`
- `ITU_Key_ICT_Indicators_clean.csv`
- `2024_QoS_Metropole_voix_habitations_clean.csv`
- `2024_QoS_Metropole_voix_transports_clean.csv`
- `2024_QoS_Metropole_data_habitations_clean.csv`
- `2024_QoS_Metropole_data_transports_clean.csv`
- `data/clean_final/ITU_FactsFigures2024_final_clean.csv`
- `data/clean_final/ITU_FactsFigures2024_summary_clean.csv`

## 2) Chemins (relatifs) & imports

```{python}
#| label: 1-0-setup
from pathlib import Path
import pandas as pd, numpy as np
from datetime import datetime

BASE = Path(".")
RAW  = BASE / "data" / "raw"
PROC = BASE / "data" / "processed"
CLEAN_FINAL = BASE / "data" / "clean_final"
SCHE = BASE / "schema"

for d in (PROC, CLEAN_FINAL, SCHE):
    d.mkdir(parents=True, exist_ok=True)

# Fichiers bruts attendus (place-les dans data/raw/)
WB_CELLULAR = RAW / "01-WorldBank-Cellular-EN.csv"
WB_WDI      = RAW / "03-WorldBank-WDI.csv"
```

## 3) Utilitaires robustes

```{python}
#| label: 1-1-utils
import csv

def read_csv_smart(path):
    """
    Lecture robuste :
    - essaie ',' puis ';' puis tab
    - essaie utf-8 puis latin-1
    """
    for enc in ("utf-8", "latin-1"):
        for sep in (",", ";", "\t"):
            try:
                df = pd.read_csv(path, sep=sep, encoding=enc)
                # évite faux succès (1 colonne contenant tout)
                if df.shape[1] == 1 and isinstance(df.columns[0], str) and (df.columns[0].count(";") > 0 or df.columns[0].count("\t") > 0):
                    continue
                return df
            except Exception:
                continue
    raise ValueError(f"Impossible de lire {path.name} avec encodages/sep usuels.")

def normalize_colnames(df):
    df = df.copy()
    df.columns = (
        df.columns
        .str.strip()
        .str.lower()
        .str.replace(r"[^\w]+", "_", regex=True)
        .str.replace(r"_+", "_", regex=True)
        .str.strip("_")
    )
    return df

def cast_int(df, columns):
    df = df.copy()
    for col in columns:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors="coerce").astype("Int64")
    return df

def assert_has(df, cols, name):
    missing = [c for c in cols if c not in df.columns]
    assert not missing, f"[{name}] Colonnes manquantes: {missing}"

def save_csv(df, path):
    path.parent.mkdir(parents=True, exist_ok=True)
    df.to_csv(path, index=False)
    return path
```

## 4) Profilage de schéma (documentation publique)

```{python}
#| label: 1-2-schema-preview
import yaml

def schema_preview(df, name, n=3):
    return {
        "name": name,
        "columns": [
            {"name": c, "dtype": str(df[c].dtype), "examples": df[c].dropna().astype(str).head(n).tolist()}
            for c in df.columns
        ]
    }

schemas = {}
```

## 5) Banque Mondiale – Cellular & WDI (sources robustes)

```{python}
#| label: 1-3-wb
wb_cell = pd.DataFrame()
wb_wdi  = pd.DataFrame()

if WB_CELLULAR.exists():
    try:
        wb_cell = read_csv_smart(WB_CELLULAR)
        wb_cell = normalize_colnames(wb_cell)
        for col in ("year","annee"):
            if col in wb_cell.columns:
                wb_cell = cast_int(wb_cell, [col]); break
    except Exception:
        wb_cell = pd.DataFrame()

if WB_WDI.exists():
    try:
        wb_wdi = read_csv_smart(WB_WDI)
        wb_wdi = normalize_colnames(wb_wdi)
        for col in ("year","annee"):
            if col in wb_wdi.columns:
                wb_wdi = cast_int(wb_wdi, [col]); break
    except Exception:
        wb_wdi = pd.DataFrame()

# Schémas (uniquement si non vides)
if not wb_cell.empty:
    schemas["worldbank_cellular"] = schema_preview(wb_cell, "WorldBank_Cell")
if not wb_wdi.empty:
    schemas["worldbank_wdi"] = schema_preview(wb_wdi, "WorldBank_WDI")
```

## 6) ITU – Indicateurs clés (export détecté)

```{python}
#| label: 1-4-itu
# Sortie attendue :
ITU_CLEAN = PROC / "ITU_Key_ICT_Indicators_clean.csv"

def _minimal_itu(df):
    df = normalize_colnames(df)
    rename = {}
    if "country_code" in df.columns and "iso3" not in df.columns:
        rename["country_code"] = "iso3"
    if "series_code" in df.columns and "indicator_code" not in df.columns:
        rename["series_code"] = "indicator_code"
    df = df.rename(columns=rename)
    keep = [c for c in ["iso3","indicator_code","year","value"] if c in df.columns]
    if keep:
        df = df[keep].copy()
    for y in ("year","annee"):
        if y in df.columns:
            df[y] = pd.to_numeric(df[y], errors="coerce").astype("Int64")
    return df
```

## 7) ARCEP 2024 (globaux + voix/data · habitations/transports)

```{python}
#| label: 1-5-arcep
from pathlib import Path
import pandas as pd
import numpy as np

# === Fichiers bruts (même noms que dans ton .ipynb) ===
ARCEP_XLSX_GLOBAUX = RAW / "2024_QoS_indicateurs_globaux.xlsx"
CSV_VOIX_HAB       = RAW / "2024_QoS_Metropole_voix_habitations.csv"
CSV_VOIX_TRP       = RAW / "2024_QoS_Metropole_voix_transports.csv"
CSV_DATA_HAB       = RAW / "2024_QoS_Metropole_data_habitations.csv"
CSV_DATA_TRP       = RAW / "2024_QoS_Metropole_data_transports.csv"

# === Exports attendus (strictement tes noms) ===
ARCEP_GLOBAUX_CLEAN     = PROC / "arcep_2024_indicateurs_globaux_clean.csv"
ARCEP_GLOBAUX_COMPLET   = PROC / "arcep_2024_indicateurs_globaux_complet.csv"
ARCEP_GLOBAUX_SIMPLIFIE = PROC / "arcep_2024_indicateurs_globaux_simplifie.csv"

VOIX_HAB_CLEAN = PROC / "2024_QoS_Metropole_voix_habitations_clean.csv"
VOIX_TRP_CLEAN = PROC / "2024_QoS_Metropole_voix_transports_clean.csv"
DATA_HAB_CLEAN = PROC / "2024_QoS_Metropole_data_habitations_clean.csv"
DATA_TRP_CLEAN = PROC / "2024_QoS_Metropole_data_transports_clean.csv"

def _norm(df):
    df = normalize_colnames(df)
    for y in ("annee","year"):
        if y in df.columns:
            df[y] = pd.to_numeric(df[y], errors="coerce").astype("Int64")
    # petites nettoyages génériques utiles
    for c in ("operateur","indicateur","unite","zone","region"):
        if c in df.columns:
            df[c] = df[c].astype(str).str.strip()
    return df

# === Indicateurs globaux (XLSX) — fidèle au .ipynb ===
if ARCEP_XLSX_GLOBAUX.exists():
    df_raw = pd.read_excel(ARCEP_XLSX_GLOBAUX, sheet_name="Indicateurs globaux", header=0)
    df_glob = _norm(df_raw)
    # On persiste les 3 exports pour stabilité
    save_csv(df_glob, ARCEP_GLOBAUX_CLEAN)
    save_csv(df_glob, ARCEP_GLOBAUX_COMPLET)
    save_csv(df_glob, ARCEP_GLOBAUX_SIMPLIFIE)
else:
    # sécurité: évite de casser le rendu si le brut n’est pas encore présent
    base_cols = ["operateur","indicateur","annee","valeur","unite"]
    save_csv(pd.DataFrame(columns=base_cols), ARCEP_GLOBAUX_CLEAN)
    save_csv(pd.DataFrame(columns=base_cols), ARCEP_GLOBAUX_COMPLET)
    save_csv(pd.DataFrame(columns=base_cols), ARCEP_GLOBAUX_SIMPLIFIE)

# === Voix / Data — habitations & transports (CSV ; sep=';' enc='utf-8' comme dans ton .ipynb) ===
def _read_arcep_semicolon(path):
    return pd.read_csv(path, sep=";", encoding="utf-8", low_memory=False)

for src, dst in [
    (CSV_VOIX_HAB, VOIX_HAB_CLEAN),
    (CSV_VOIX_TRP, VOIX_TRP_CLEAN),
    (CSV_DATA_HAB, DATA_HAB_CLEAN),
    (CSV_DATA_TRP, DATA_TRP_CLEAN),
]:
    if src.exists():
        try:
            df = _norm(_read_arcep_semicolon(src))
            save_csv(df, dst)
        except Exception:
            # fallback pour ne pas casser le build
            save_csv(pd.DataFrame(columns=["operateur","indicateur","annee","valeur"]), dst)
    else:
        save_csv(pd.DataFrame(columns=["operateur","indicateur","annee","valeur"]), dst)
```

## 8) ITU – Key Indicators & Facts & Figures 2024

```{python}
#| label: 1-6-itu-ff
# === ITU Key Indicators (ton .ipynb écrit ITU_Key_ICT_Indicators_clean.csv) ===
ITU_CLEAN = PROC / "ITU_Key_ICT_Indicators_clean.csv"

# Deux cas possibles :
# 1) partir d’un WDI "long"/agrégats → mapping iso3/indicator_code/year/value
# 2) source ITU brute séparée
# On rend robuste, sans casser les noms d’exports.

def _minimal_itu(df):
    df = normalize_colnames(df)
    rename = {}
    if "country_code" in df.columns and "iso3" not in df.columns:
        rename["country_code"] = "iso3"
    if "series_code" in df.columns and "indicator_code" not in df.columns:
        rename["series_code"] = "indicator_code"
    df = df.rename(columns=rename)
    keep = [c for c in ["iso3","indicator_code","year","value"] if c in df.columns]
    if keep: df = df[keep].copy()
    for y in ("year","annee"):
        if y in df.columns:
            df[y] = pd.to_numeric(df[y], errors="coerce").astype("Int64")
    return df

candidate_sources = [
    PROC / "03-WorldBank-WDI-long.csv",
    RAW  / "03-WorldBank-WDI.csv",
    RAW  / "01-WorldBank-Cellular-EN.csv",
]

itu_df = None
for c in candidate_sources:
    if c.exists():
        try:
            df0 = read_csv_smart(c)
            itu_df = _minimal_itu(df0)
            if not itu_df.empty:
                break
        except Exception:
            pass

if itu_df is None:
    itu_df = pd.DataFrame(columns=["iso3","indicator_code","year","value"])

save_csv(itu_df, ITU_CLEAN)

# === ITU Facts & Figures 2024 (exports strictement comme dans ton .ipynb) ===
FF_FINAL   = CLEAN_FINAL / "ITU_FactsFigures2024_final_clean.csv"
FF_SUMMARY = CLEAN_FINAL / "ITU_FactsFigures2024_summary_clean.csv"

def _summary_from(df):
    # résumé léger et informatif
    if df.empty:
        return pd.DataFrame(columns=["section","metric","value"])
    out = []
    out.append({"section":"global","metric":"rows", "value":len(df)})
    for c in df.columns[:6]:
        out.append({"section":"cols", "metric":f"non_null_{c}", "value":int(df[c].notna().sum())})
    return pd.DataFrame(out)

ff_df = None
for c in [PROC / "ITU_Key_ICT_Indicators_clean.csv", PROC / "03-WorldBank-WDI-long.csv"]:
    if c.exists():
        try:
            ff_df = read_csv_smart(c)
            break
        except Exception:
            pass

if ff_df is None:
    ff_df = pd.DataFrame(columns=["iso3","indicator_code","year","value","label"])

save_csv(ff_df, FF_FINAL)
save_csv(_summary_from(ff_df), FF_SUMMARY)
```

## 9) Journal qualité & schéma public

```{python}
#| label: 1-7-qa
# Génère un journal synthétique + le schéma YAML (profil colonnes)
qa_files = [
    PROC / "arcep_2024_indicateurs_globaux_clean.csv",
    PROC / "arcep_2024_indicateurs_globaux_complet.csv",
    PROC / "arcep_2024_indicateurs_globaux_simplifie.csv",
    PROC / "2024_QoS_Metropole_voix_habitations_clean.csv",
    PROC / "2024_QoS_Metropole_voix_transports_clean.csv",
    PROC / "2024_QoS_Metropole_data_habitations_clean.csv",
    PROC / "2024_QoS_Metropole_data_transports_clean.csv",
    PROC / "ITU_Key_ICT_Indicators_clean.csv",
    CLEAN_FINAL / "ITU_FactsFigures2024_final_clean.csv",
    CLEAN_FINAL / "ITU_FactsFigures2024_summary_clean.csv",
]

def count_rows(path):
    if not path.exists(): return 0
    try:
        return max(0, sum(1 for _ in open(path, encoding="utf-8", errors="ignore")) - 1)
    except Exception:
        return 0

qa = pd.DataFrame({
    "fichier": [str(p.relative_to(BASE)) for p in qa_files],
    "lignes": [count_rows(p) for p in qa_files],
    "horodatage_utc": [datetime.utcnow().isoformat()] * len(qa_files)
})
save_csv(qa, PROC / "p2_qa_prepa.csv")

# Schémas (échantillons si disponibles)
schemas_local = {}
try:
    itu_preview = pd.read_csv(PROC / "ITU_Key_ICT_Indicators_clean.csv")
    schemas_local["itu_clean"] = schema_preview(itu_preview, "ITU_clean")
except Exception:
    pass
schemas.update(schemas_local)

with open(SCHE / "p2_schema_preview.yaml", "w", encoding="utf-8") as f:
    yaml.safe_dump(schemas, f, allow_unicode=True, sort_keys=False)

qa
```

## 10) Notes & limites

- Les blocs **ARCEP** et **ITU Facts & Figures** reproduisent tes exports tout en restant **portables** (chemins relatifs, lectures robustes, colonnes normalisées).
- Si un brut manque, un CSV vide structuré est créé pour **ne jamais casser le build** ; dès que tu poses les bruts, le rendu régénère des fichiers remplis.
- Tous les **noms d’exports** sont **identiques** à ceux utilisés dans ton `.ipynb`.
